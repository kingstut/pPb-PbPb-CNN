{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install --user keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install --user tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install --user keras==1.2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.initializations import normal\n",
    "from keras.layers.advanced_activations import LeakyReLU, PReLU, ELU\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Activation, Input, Flatten\n",
    "from keras.optimizers import SGD, Adam, Adamax\n",
    "from keras.constraints import maxnorm\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import AveragePooling2D, MaxPooling2D\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import model_from_json\n",
    "from keras.regularizers import l2, activity_l2, l1\n",
    "\n",
    "from keras.callbacks import History \n",
    "\n",
    "\n",
    "seed = 13\n",
    "np.random.seed(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install --user import_ipynb\n",
    "! pip install --user pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape= (120,)\n",
      "shape= ()\n",
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " ...\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "##### load training and testing dataset\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import import_ipynb\n",
    "import pandas as pds\n",
    "def load_data(csv_path, shuffle=True):\n",
    "    dat = pds.read_csv(csv_path)\n",
    "    x_origin = dat.iloc[:, range(0, 6*20)].values\n",
    "    y_origin = dat.loc[:, 'collision_system'].values\n",
    "    if shuffle == True:\n",
    "        randomize = np.arange(len(x_origin))\n",
    "        np.random.shuffle(randomize)\n",
    "        x = x_origin[randomize]\n",
    "        y = y_origin[randomize]\n",
    "\n",
    "    #x, y, randomize = regulize(x_origin, y_origin)\n",
    "    return x, y\n",
    "\n",
    "\n",
    "x_train, y_train = load_data('train_data.csv')\n",
    "n_train = len(x_train)\n",
    "\n",
    "x_test, y_test = load_data('testing_data.csv')\n",
    "n_test = len(x_test)\n",
    "\n",
    "height, width = 20, 6\n",
    "\n",
    "print('shape=', x_train[0].shape)\n",
    "print('shape=', y_train[0].shape)\n",
    "y_train = to_categorical(y_train)\n",
    "y_test= to_categorical(y_test)\n",
    "print(y_train)\n",
    "\n",
    "x_train = x_train.reshape(n_train, height, width, 1).astype('float32')\n",
    "x_test = x_test.reshape(n_test, height, width, 1).astype('float32')\n",
    "\n",
    "nb_classes = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==1.15.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/2b/e3af15221da9ff323521565fa3324b0d7c7c5b1d7a8ca66984c8d59cb0ce/tensorflow-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl (412.3MB)\n",
      "\u001b[K     |████████████████████████████████| 412.3MB 108kB/s  eta 0:00:01    |█▉                              | 23.4MB 12.7MB/s eta 0:00:31     |███████████████▏                | 195.3MB 70.3MB/s eta 0:00:04     |███████████████████▏            | 246.5MB 69.6MB/s eta 0:00:03     |███████████████████▍            | 249.8MB 69.6MB/s eta 0:00:03     |███████████████████████▊        | 305.6MB 60.0MB/s eta 0:00:02     |█████████████████████████▉      | 332.8MB 55.8MB/s eta 0:00:02     |██████████████████████████▎     | 339.1MB 55.8MB/s eta 0:00:02\n",
      "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.16.0 in /global/common/cori_cle7/software/jupyter/19-11/lib/python3.7/site-packages (from tensorflow==1.15.0) (1.17.3)\n",
      "Collecting tensorflow-estimator==1.15.1 (from tensorflow==1.15.0)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
      "\u001b[K     |████████████████████████████████| 512kB 64.4MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /global/common/cori_cle7/software/jupyter/19-11/lib/python3.7/site-packages (from tensorflow==1.15.0) (0.33.4)\n",
      "Collecting tensorboard<1.16.0,>=1.15.0 (from tensorflow==1.15.0)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
      "\u001b[K     |████████████████████████████████| 3.8MB 61.2MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /global/u2/s/stuti/.local/lib/python3.7/site-packages (from tensorflow==1.15.0) (1.1.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /global/u2/s/stuti/.local/lib/python3.7/site-packages (from tensorflow==1.15.0) (1.28.1)\n",
      "Requirement already satisfied: six>=1.10.0 in /global/common/cori_cle7/software/jupyter/19-11/lib/python3.7/site-packages (from tensorflow==1.15.0) (1.12.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /global/u2/s/stuti/.local/lib/python3.7/site-packages (from tensorflow==1.15.0) (3.2.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /global/u2/s/stuti/.local/lib/python3.7/site-packages (from tensorflow==1.15.0) (0.2.0)\n",
      "Requirement already satisfied: gast==0.2.2 in /global/u2/s/stuti/.local/lib/python3.7/site-packages (from tensorflow==1.15.0) (0.2.2)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /global/u2/s/stuti/.local/lib/python3.7/site-packages (from tensorflow==1.15.0) (1.12.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /global/u2/s/stuti/.local/lib/python3.7/site-packages (from tensorflow==1.15.0) (1.1.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /global/u2/s/stuti/.local/lib/python3.7/site-packages (from tensorflow==1.15.0) (0.9.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in /global/u2/s/stuti/.local/lib/python3.7/site-packages (from tensorflow==1.15.0) (0.8.1)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in /global/u2/s/stuti/.local/lib/python3.7/site-packages (from tensorflow==1.15.0) (1.0.8)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /global/u2/s/stuti/.local/lib/python3.7/site-packages (from tensorflow==1.15.0) (3.11.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /global/u2/s/stuti/.local/lib/python3.7/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (41.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /global/u2/s/stuti/.local/lib/python3.7/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.2.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /global/u2/s/stuti/.local/lib/python3.7/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (1.0.1)\n",
      "Requirement already satisfied: h5py in /global/u2/s/stuti/.local/lib/python3.7/site-packages (from keras-applications>=1.0.8->tensorflow==1.15.0) (2.10.0)\n",
      "Installing collected packages: tensorflow-estimator, tensorboard, tensorflow\n",
      "  Found existing installation: tensorflow-estimator 2.1.0\n",
      "    Uninstalling tensorflow-estimator-2.1.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.1.0\n",
      "  Found existing installation: tensorboard 2.1.1\n",
      "    Uninstalling tensorboard-2.1.1:\n",
      "      Successfully uninstalled tensorboard-2.1.1\n",
      "\u001b[33m  WARNING: The script tensorboard is installed in '/global/homes/s/stuti/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "  Found existing installation: tensorflow 2.1.0\n",
      "    Uninstalling tensorflow-2.1.0:\n",
      "      Successfully uninstalled tensorflow-2.1.0\n",
      "\u001b[33m  WARNING: The scripts estimator_ckpt_converter, freeze_graph, saved_model_cli, tensorboard, tf_upgrade_v2, tflite_convert, toco and toco_from_protos are installed in '/global/homes/s/stuti/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "Successfully installed tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --user tensorflow==1.15.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: failed\n",
      "\n",
      "PackagesNotFoundError: The following packages are missing from the target environment:\n",
      "  - tensorflow\n",
      "  - tensorflow-base\n",
      "  - tensorflow-gpu\n",
      "\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda remove tensorflow-gpu tensorflow tensorflow-base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /global/homes/s/stuti/.local/lib/python3.7/site-packages/tensorflow_core/python/compat/v2_compat.py:68: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "WARNING:tensorflow:From /global/homes/s/stuti/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:321: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /global/homes/s/stuti/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:673: calling RandomNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /global/homes/s/stuti/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1029: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /global/homes/s/stuti/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:491: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /global/homes/s/stuti/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:73: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /global/homes/s/stuti/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:2516: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /global/homes/s/stuti/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:2868: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /global/homes/s/stuti/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1047: calling reduce_prod_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /global/homes/s/stuti/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:634: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "##### define the layer stacks\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "model = Sequential()\n",
    "\n",
    "# used for LeakyReLU\n",
    "leaky_alpha = 0.3\n",
    "\n",
    "\n",
    "\n",
    "model.add(Convolution2D(18, 3,3, border_mode='same',\n",
    "                        input_shape=(height, width, 1),\n",
    "                        init='normal',\n",
    "                        W_regularizer=l2(0.01))\n",
    "                        )\n",
    "\n",
    "model.add(BatchNormalization(mode=0, axis=3))\n",
    "model.add(PReLU())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Convolution2D(32, 2, 2,\n",
    "                border_mode='same',\n",
    "                init='normal',\n",
    "                W_regularizer=l2(0.01)))\n",
    "\n",
    "model.add(AveragePooling2D(pool_size=(2, 2), strides=(2, 2), border_mode='same', dim_ordering='default'))\n",
    "model.add(BatchNormalization(mode=0, axis=3))\n",
    "model.add(PReLU())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, W_regularizer=l2(0.01), init='normal'))\n",
    "model.add(BatchNormalization(mode=0))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "adm = Adamax(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=1.0E-6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /global/homes/s/stuti/.local/lib/python3.7/site-packages/keras/optimizers.py:658: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /global/homes/s/stuti/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:2389: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /global/homes/s/stuti/.local/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /global/homes/s/stuti/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:740: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:Variable *= will be deprecated. Use `var.assign(var * other)` if you want assignment to the variable value or `x = x * y` if you want a new python Tensor object.\n",
      "WARNING:tensorflow:From /global/homes/s/stuti/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:736: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Train on 38678 samples, validate on 4298 samples\n",
      "Epoch 1/200\n",
      "WARNING:tensorflow:From /global/homes/s/stuti/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:112: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /global/homes/s/stuti/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:120: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /global/homes/s/stuti/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:122: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /global/homes/s/stuti/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:269: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /global/homes/s/stuti/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:281: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "38592/38678 [============================>.] - ETA: 0s - loss: 3.0262 - acc: 0.5635Epoch 00000: val_loss improved from inf to 2.30244, saving model to weights_filter.hdf5\n",
      "38678/38678 [==============================] - 18s - loss: 3.0250 - acc: 0.5634 - val_loss: 2.3024 - val_acc: 0.6087\n",
      "Epoch 2/200\n",
      "38656/38678 [============================>.] - ETA: 0s - loss: 2.0572 - acc: 0.5769Epoch 00001: val_loss improved from 2.30244 to 1.68288, saving model to weights_filter.hdf5\n",
      "38678/38678 [==============================] - 16s - loss: 2.0571 - acc: 0.5769 - val_loss: 1.6829 - val_acc: 0.6366\n",
      "Epoch 3/200\n",
      "38656/38678 [============================>.] - ETA: 0s - loss: 1.6115 - acc: 0.5792Epoch 00002: val_loss improved from 1.68288 to 1.37373, saving model to weights_filter.hdf5\n",
      "38678/38678 [==============================] - 17s - loss: 1.6114 - acc: 0.5792 - val_loss: 1.3737 - val_acc: 0.6345\n",
      "Epoch 4/200\n",
      "38592/38678 [============================>.] - ETA: 0s - loss: 1.3595 - acc: 0.5873Epoch 00003: val_loss improved from 1.37373 to 1.18787, saving model to weights_filter.hdf5\n",
      "38678/38678 [==============================] - 17s - loss: 1.3594 - acc: 0.5872 - val_loss: 1.1879 - val_acc: 0.6345\n",
      "Epoch 5/200\n",
      "38464/38678 [============================>.] - ETA: 0s - loss: 1.2013 - acc: 0.5892Epoch 00004: val_loss improved from 1.18787 to 1.06814, saving model to weights_filter.hdf5\n",
      "38678/38678 [==============================] - 11s - loss: 1.2008 - acc: 0.5892 - val_loss: 1.0681 - val_acc: 0.6345\n",
      "Epoch 6/200\n",
      "38656/38678 [============================>.] - ETA: 0s - loss: 1.0947 - acc: 0.5894Epoch 00005: val_loss improved from 1.06814 to 0.98264, saving model to weights_filter.hdf5\n",
      "38678/38678 [==============================] - 10s - loss: 1.0946 - acc: 0.5894 - val_loss: 0.9826 - val_acc: 0.6363\n",
      "Epoch 7/200\n",
      "38656/38678 [============================>.] - ETA: 0s - loss: 1.0153 - acc: 0.5932Epoch 00006: val_loss improved from 0.98264 to 0.91964, saving model to weights_filter.hdf5\n",
      "38678/38678 [==============================] - 15s - loss: 1.0153 - acc: 0.5932 - val_loss: 0.9196 - val_acc: 0.6366\n",
      "Epoch 8/200\n",
      "38656/38678 [============================>.] - ETA: 0s - loss: 0.9499 - acc: 0.5969Epoch 00007: val_loss improved from 0.91964 to 0.87055, saving model to weights_filter.hdf5\n",
      "38678/38678 [==============================] - 16s - loss: 0.9498 - acc: 0.5970 - val_loss: 0.8705 - val_acc: 0.6366\n",
      "Epoch 9/200\n",
      "38656/38678 [============================>.] - ETA: 0s - loss: 0.9055 - acc: 0.5987Epoch 00008: val_loss improved from 0.87055 to 0.83353, saving model to weights_filter.hdf5\n",
      "38678/38678 [==============================] - 16s - loss: 0.9055 - acc: 0.5987 - val_loss: 0.8335 - val_acc: 0.6370\n",
      "Epoch 10/200\n",
      "38592/38678 [============================>.] - ETA: 0s - loss: 0.8624 - acc: 0.6068Epoch 00009: val_loss improved from 0.83353 to 0.80353, saving model to weights_filter.hdf5\n",
      "38678/38678 [==============================] - 16s - loss: 0.8625 - acc: 0.6067 - val_loss: 0.8035 - val_acc: 0.6382\n",
      "Epoch 11/200\n",
      "38592/38678 [============================>.] - ETA: 0s - loss: 0.8358 - acc: 0.6006Epoch 00010: val_loss improved from 0.80353 to 0.77980, saving model to weights_filter.hdf5\n",
      "38678/38678 [==============================] - 13s - loss: 0.8358 - acc: 0.6005 - val_loss: 0.7798 - val_acc: 0.6368\n",
      "Epoch 12/200\n",
      "38656/38678 [============================>.] - ETA: 0s - loss: 0.8098 - acc: 0.6041Epoch 00011: val_loss improved from 0.77980 to 0.76039, saving model to weights_filter.hdf5\n",
      "38678/38678 [==============================] - 10s - loss: 0.8098 - acc: 0.6040 - val_loss: 0.7604 - val_acc: 0.6352\n",
      "Epoch 13/200\n",
      "38656/38678 [============================>.] - ETA: 0s - loss: 0.7841 - acc: 0.6093Epoch 00012: val_loss improved from 0.76039 to 0.74367, saving model to weights_filter.hdf5\n",
      "38678/38678 [==============================] - 13s - loss: 0.7842 - acc: 0.6092 - val_loss: 0.7437 - val_acc: 0.6368\n",
      "Epoch 14/200\n",
      "38656/38678 [============================>.] - ETA: 0s - loss: 0.7711 - acc: 0.6101Epoch 00013: val_loss improved from 0.74367 to 0.73091, saving model to weights_filter.hdf5\n",
      "38678/38678 [==============================] - 16s - loss: 0.7711 - acc: 0.6101 - val_loss: 0.7309 - val_acc: 0.6363\n",
      "Epoch 15/200\n",
      "38656/38678 [============================>.] - ETA: 0s - loss: 0.7524 - acc: 0.6141Epoch 00014: val_loss improved from 0.73091 to 0.71916, saving model to weights_filter.hdf5\n",
      "38678/38678 [==============================] - 16s - loss: 0.7523 - acc: 0.6141 - val_loss: 0.7192 - val_acc: 0.6340\n",
      "Epoch 16/200\n",
      "38656/38678 [============================>.] - ETA: 0s - loss: 0.7389 - acc: 0.6138Epoch 00015: val_loss improved from 0.71916 to 0.70990, saving model to weights_filter.hdf5\n",
      "38678/38678 [==============================] - 16s - loss: 0.7389 - acc: 0.6137 - val_loss: 0.7099 - val_acc: 0.6363\n",
      "Epoch 17/200\n",
      "38592/38678 [============================>.] - ETA: 0s - loss: 0.7268 - acc: 0.6185Epoch 00016: val_loss improved from 0.70990 to 0.70223, saving model to weights_filter.hdf5\n",
      "38678/38678 [==============================] - 14s - loss: 0.7270 - acc: 0.6184 - val_loss: 0.7022 - val_acc: 0.6366\n",
      "Epoch 18/200\n",
      "38528/38678 [============================>.] - ETA: 0s - loss: 0.7189 - acc: 0.6171Epoch 00017: val_loss improved from 0.70223 to 0.69442, saving model to weights_filter.hdf5\n",
      "38678/38678 [==============================] - 9s - loss: 0.7190 - acc: 0.6169 - val_loss: 0.6944 - val_acc: 0.6363\n",
      "Epoch 19/200\n",
      "38592/38678 [============================>.] - ETA: 0s - loss: 0.7100 - acc: 0.6191Epoch 00018: val_loss improved from 0.69442 to 0.68859, saving model to weights_filter.hdf5\n",
      "38678/38678 [==============================] - 12s - loss: 0.7098 - acc: 0.6193 - val_loss: 0.6886 - val_acc: 0.6366\n",
      "Epoch 20/200\n",
      "38592/38678 [============================>.] - ETA: 0s - loss: 0.7040 - acc: 0.6193Epoch 00019: val_loss improved from 0.68859 to 0.68290, saving model to weights_filter.hdf5\n",
      "38678/38678 [==============================] - 16s - loss: 0.7040 - acc: 0.6193 - val_loss: 0.6829 - val_acc: 0.6363\n",
      "Epoch 21/200\n",
      "38592/38678 [============================>.] - ETA: 0s - loss: 0.6978 - acc: 0.6228Epoch 00020: val_loss improved from 0.68290 to 0.67961, saving model to weights_filter.hdf5\n",
      "38678/38678 [==============================] - 15s - loss: 0.6979 - acc: 0.6227 - val_loss: 0.6796 - val_acc: 0.6347\n",
      "Epoch 22/200\n",
      "38592/38678 [============================>.] - ETA: 0s - loss: 0.6917 - acc: 0.6235Epoch 00021: val_loss improved from 0.67961 to 0.67651, saving model to weights_filter.hdf5\n",
      "38678/38678 [==============================] - 16s - loss: 0.6916 - acc: 0.6235 - val_loss: 0.6765 - val_acc: 0.6121\n",
      "Epoch 23/200\n",
      "38592/38678 [============================>.] - ETA: 0s - loss: 0.6852 - acc: 0.6244Epoch 00022: val_loss improved from 0.67651 to 0.67226, saving model to weights_filter.hdf5\n",
      "38678/38678 [==============================] - 15s - loss: 0.6852 - acc: 0.6245 - val_loss: 0.6723 - val_acc: 0.6368\n",
      "Epoch 24/200\n",
      "38464/38678 [============================>.] - ETA: 0s - loss: 0.6812 - acc: 0.6252Epoch 00023: val_loss improved from 0.67226 to 0.66821, saving model to weights_filter.hdf5\n",
      "38678/38678 [==============================] - 10s - loss: 0.6810 - acc: 0.6255 - val_loss: 0.6682 - val_acc: 0.6363\n",
      "Epoch 25/200\n",
      "38592/38678 [============================>.] - ETA: 0s - loss: 0.6786 - acc: 0.6232Epoch 00024: val_loss improved from 0.66821 to 0.66653, saving model to weights_filter.hdf5\n",
      "38678/38678 [==============================] - 11s - loss: 0.6786 - acc: 0.6233 - val_loss: 0.6665 - val_acc: 0.6361\n",
      "Epoch 26/200\n",
      "38528/38678 [============================>.] - ETA: 0s - loss: 0.6764 - acc: 0.6241Epoch 00025: val_loss improved from 0.66653 to 0.66432, saving model to weights_filter.hdf5\n",
      "38678/38678 [==============================] - 15s - loss: 0.6763 - acc: 0.6241 - val_loss: 0.6643 - val_acc: 0.6347\n",
      "Epoch 27/200\n",
      "38656/38678 [============================>.] - ETA: 0s - loss: 0.6722 - acc: 0.6257Epoch 00026: val_loss improved from 0.66432 to 0.66192, saving model to weights_filter.hdf5\n",
      "38678/38678 [==============================] - 16s - loss: 0.6723 - acc: 0.6257 - val_loss: 0.6619 - val_acc: 0.6366\n",
      "Epoch 28/200\n",
      "38528/38678 [============================>.] - ETA: 0s - loss: 0.6685 - acc: 0.6287Epoch 00027: val_loss improved from 0.66192 to 0.66018, saving model to weights_filter.hdf5\n",
      "38678/38678 [==============================] - 16s - loss: 0.6684 - acc: 0.6287 - val_loss: 0.6602 - val_acc: 0.6366\n",
      "Epoch 29/200\n",
      "38656/38678 [============================>.] - ETA: 0s - loss: 0.6672 - acc: 0.6261Epoch 00028: val_loss improved from 0.66018 to 0.65868, saving model to weights_filter.hdf5\n",
      "38678/38678 [==============================] - 16s - loss: 0.6672 - acc: 0.6262 - val_loss: 0.6587 - val_acc: 0.6377\n",
      "Epoch 30/200\n",
      "38528/38678 [============================>.] - ETA: 0s - loss: 0.6639 - acc: 0.6304Epoch 00029: val_loss improved from 0.65868 to 0.65716, saving model to weights_filter.hdf5\n",
      "38678/38678 [==============================] - 11s - loss: 0.6638 - acc: 0.6306 - val_loss: 0.6572 - val_acc: 0.6347\n",
      "Epoch 31/200\n",
      "38656/38678 [============================>.] - ETA: 0s - loss: 0.6624 - acc: 0.6290Epoch 00030: val_loss improved from 0.65716 to 0.65641, saving model to weights_filter.hdf5\n",
      "38678/38678 [==============================] - 10s - loss: 0.6624 - acc: 0.6290 - val_loss: 0.6564 - val_acc: 0.6349\n",
      "Epoch 32/200\n",
      "38528/38678 [============================>.] - ETA: 0s - loss: 0.6606 - acc: 0.6310Epoch 00031: val_loss improved from 0.65641 to 0.65571, saving model to weights_filter.hdf5\n",
      "38678/38678 [==============================] - 14s - loss: 0.6606 - acc: 0.6310 - val_loss: 0.6557 - val_acc: 0.6366\n",
      "Epoch 33/200\n",
      "38592/38678 [============================>.] - ETA: 0s - loss: 0.6596 - acc: 0.6286Epoch 00032: val_loss improved from 0.65571 to 0.65360, saving model to weights_filter.hdf5\n",
      "38678/38678 [==============================] - 15s - loss: 0.6595 - acc: 0.6288 - val_loss: 0.6536 - val_acc: 0.6380\n",
      "Epoch 34/200\n",
      "38592/38678 [============================>.] - ETA: 0s - loss: 0.6590 - acc: 0.6276Epoch 00033: val_loss improved from 0.65360 to 0.65331, saving model to weights_filter.hdf5\n",
      "38678/38678 [==============================] - 16s - loss: 0.6590 - acc: 0.6276 - val_loss: 0.6533 - val_acc: 0.6368\n",
      "Epoch 35/200\n",
      "38656/38678 [============================>.] - ETA: 0s - loss: 0.6558 - acc: 0.6310Epoch 00034: val_loss improved from 0.65331 to 0.65175, saving model to weights_filter.hdf5\n",
      "38678/38678 [==============================] - 16s - loss: 0.6558 - acc: 0.6311 - val_loss: 0.6517 - val_acc: 0.6363\n",
      "Epoch 36/200\n",
      "38592/38678 [============================>.] - ETA: 0s - loss: 0.6569 - acc: 0.6294Epoch 00035: val_loss improved from 0.65175 to 0.65145, saving model to weights_filter.hdf5\n",
      "38678/38678 [==============================] - 13s - loss: 0.6570 - acc: 0.6293 - val_loss: 0.6514 - val_acc: 0.6363\n",
      "Epoch 37/200\n",
      "38656/38678 [============================>.] - ETA: 0s - loss: 0.6554 - acc: 0.6309Epoch 00036: val_loss improved from 0.65145 to 0.65142, saving model to weights_filter.hdf5\n",
      "38678/38678 [==============================] - 10s - loss: 0.6554 - acc: 0.6310 - val_loss: 0.6514 - val_acc: 0.6340\n",
      "Epoch 38/200\n",
      "38656/38678 [============================>.] - ETA: 0s - loss: 0.6538 - acc: 0.6320Epoch 00037: val_loss improved from 0.65142 to 0.65059, saving model to weights_filter.hdf5\n",
      "38678/38678 [==============================] - 12s - loss: 0.6538 - acc: 0.6320 - val_loss: 0.6506 - val_acc: 0.6401\n",
      "Epoch 39/200\n",
      "38656/38678 [============================>.] - ETA: 0s - loss: 0.6538 - acc: 0.6315Epoch 00038: val_loss improved from 0.65059 to 0.65045, saving model to weights_filter.hdf5\n",
      "38678/38678 [==============================] - 15s - loss: 0.6538 - acc: 0.6315 - val_loss: 0.6504 - val_acc: 0.6345\n",
      "Epoch 40/200\n",
      "38656/38678 [============================>.] - ETA: 0s - loss: 0.6538 - acc: 0.6304Epoch 00039: val_loss improved from 0.65045 to 0.64895, saving model to weights_filter.hdf5\n",
      "38678/38678 [==============================] - 16s - loss: 0.6538 - acc: 0.6304 - val_loss: 0.6489 - val_acc: 0.6363\n",
      "Epoch 41/200\n",
      "38528/38678 [============================>.] - ETA: 0s - loss: 0.6527 - acc: 0.6312Epoch 00040: val_loss improved from 0.64895 to 0.64858, saving model to weights_filter.hdf5\n",
      "38678/38678 [==============================] - 16s - loss: 0.6528 - acc: 0.6311 - val_loss: 0.6486 - val_acc: 0.6401\n",
      "Epoch 42/200\n",
      "38464/38678 [============================>.] - ETA: 0s - loss: 0.6524 - acc: 0.6320Epoch 00041: val_loss improved from 0.64858 to 0.64857, saving model to weights_filter.hdf5\n",
      "38678/38678 [==============================] - 15s - loss: 0.6523 - acc: 0.6320 - val_loss: 0.6486 - val_acc: 0.6359\n",
      "Epoch 43/200\n",
      "38464/38678 [============================>.] - ETA: 0s - loss: 0.6523 - acc: 0.6296Epoch 00042: val_loss did not improve\n",
      "38678/38678 [==============================] - 10s - loss: 0.6521 - acc: 0.6298 - val_loss: 0.6495 - val_acc: 0.6377\n",
      "Epoch 44/200\n",
      "38656/38678 [============================>.] - ETA: 0s - loss: 0.6509 - acc: 0.6323Epoch 00043: val_loss did not improve\n",
      "38678/38678 [==============================] - 11s - loss: 0.6509 - acc: 0.6323 - val_loss: 0.6490 - val_acc: 0.6377\n",
      "Epoch 45/200\n",
      "38656/38678 [============================>.] - ETA: 0s - loss: 0.6507 - acc: 0.6317Epoch 00044: val_loss improved from 0.64857 to 0.64805, saving model to weights_filter.hdf5\n",
      "38678/38678 [==============================] - 15s - loss: 0.6507 - acc: 0.6317 - val_loss: 0.6481 - val_acc: 0.6401\n",
      "Epoch 46/200\n",
      "38656/38678 [============================>.] - ETA: 0s - loss: 0.6511 - acc: 0.6313Epoch 00045: val_loss did not improve\n",
      "38678/38678 [==============================] - 16s - loss: 0.6510 - acc: 0.6314 - val_loss: 0.6481 - val_acc: 0.6380\n",
      "Epoch 47/200\n",
      "38592/38678 [============================>.] - ETA: 0s - loss: 0.6509 - acc: 0.6296Epoch 00046: val_loss improved from 0.64805 to 0.64742, saving model to weights_filter.hdf5\n",
      "38678/38678 [==============================] - 16s - loss: 0.6509 - acc: 0.6297 - val_loss: 0.6474 - val_acc: 0.6398\n",
      "Epoch 48/200\n",
      "38656/38678 [============================>.] - ETA: 0s - loss: 0.6509 - acc: 0.6311Epoch 00047: val_loss did not improve\n",
      "38678/38678 [==============================] - 16s - loss: 0.6509 - acc: 0.6310 - val_loss: 0.6491 - val_acc: 0.6340\n",
      "Epoch 49/200\n",
      "38464/38678 [============================>.] - ETA: 0s - loss: 0.6505 - acc: 0.6309Epoch 00048: val_loss did not improve\n",
      "38678/38678 [==============================] - 11s - loss: 0.6505 - acc: 0.6307 - val_loss: 0.6477 - val_acc: 0.6382\n",
      "Epoch 50/200\n",
      "38528/38678 [============================>.] - ETA: 0s - loss: 0.6505 - acc: 0.6328Epoch 00049: val_loss improved from 0.64742 to 0.64685, saving model to weights_filter.hdf5\n",
      "38678/38678 [==============================] - 9s - loss: 0.6505 - acc: 0.6328 - val_loss: 0.6469 - val_acc: 0.6384\n",
      "Epoch 51/200\n",
      "38656/38678 [============================>.] - ETA: 0s - loss: 0.6501 - acc: 0.6327Epoch 00050: val_loss did not improve\n",
      "38678/38678 [==============================] - 15s - loss: 0.6501 - acc: 0.6326 - val_loss: 0.6479 - val_acc: 0.6345\n",
      "Epoch 52/200\n",
      "38656/38678 [============================>.] - ETA: 0s - loss: 0.6504 - acc: 0.6335Epoch 00051: val_loss did not improve\n",
      "38678/38678 [==============================] - 15s - loss: 0.6504 - acc: 0.6335 - val_loss: 0.6479 - val_acc: 0.6401\n",
      "Epoch 53/200\n",
      "38528/38678 [============================>.] - ETA: 0s - loss: 0.6494 - acc: 0.6324Epoch 00052: val_loss did not improve\n",
      "38678/38678 [==============================] - 15s - loss: 0.6496 - acc: 0.6325 - val_loss: 0.6470 - val_acc: 0.6398\n",
      "Epoch 54/200\n",
      "38592/38678 [============================>.] - ETA: 0s - loss: 0.6498 - acc: 0.6334Epoch 00053: val_loss improved from 0.64685 to 0.64635, saving model to weights_filter.hdf5\n",
      "38678/38678 [==============================] - 16s - loss: 0.6497 - acc: 0.6336 - val_loss: 0.6463 - val_acc: 0.6405\n",
      "Epoch 55/200\n",
      "38464/38678 [============================>.] - ETA: 0s - loss: 0.6480 - acc: 0.6346Epoch 00054: val_loss did not improve\n",
      "38678/38678 [==============================] - 12s - loss: 0.6483 - acc: 0.6341 - val_loss: 0.6476 - val_acc: 0.6382\n",
      "Epoch 56/200\n",
      "38656/38678 [============================>.] - ETA: 0s - loss: 0.6498 - acc: 0.6316Epoch 00055: val_loss did not improve\n",
      "38678/38678 [==============================] - 10s - loss: 0.6498 - acc: 0.6316 - val_loss: 0.6466 - val_acc: 0.6403\n",
      "Epoch 57/200\n",
      "38656/38678 [============================>.] - ETA: 0s - loss: 0.6486 - acc: 0.6362Epoch 00056: val_loss improved from 0.64635 to 0.64605, saving model to weights_filter.hdf5\n",
      "38678/38678 [==============================] - 14s - loss: 0.6486 - acc: 0.6362 - val_loss: 0.6461 - val_acc: 0.6401\n",
      "Epoch 58/200\n",
      "38592/38678 [============================>.] - ETA: 0s - loss: 0.6495 - acc: 0.6329Epoch 00057: val_loss did not improve\n",
      "38678/38678 [==============================] - 15s - loss: 0.6494 - acc: 0.6330 - val_loss: 0.6465 - val_acc: 0.6403\n",
      "Epoch 59/200\n",
      "38592/38678 [============================>.] - ETA: 0s - loss: 0.6484 - acc: 0.6351Epoch 00058: val_loss improved from 0.64605 to 0.64566, saving model to weights_filter.hdf5\n",
      "38678/38678 [==============================] - 15s - loss: 0.6483 - acc: 0.6352 - val_loss: 0.6457 - val_acc: 0.6403\n",
      "Epoch 60/200\n",
      "38656/38678 [============================>.] - ETA: 0s - loss: 0.6491 - acc: 0.6336Epoch 00059: val_loss did not improve\n",
      "38678/38678 [==============================] - 15s - loss: 0.6491 - acc: 0.6336 - val_loss: 0.6457 - val_acc: 0.6401\n",
      "Epoch 61/200\n",
      "38592/38678 [============================>.] - ETA: 0s - loss: 0.6485 - acc: 0.6348Epoch 00060: val_loss did not improve\n",
      "38678/38678 [==============================] - 13s - loss: 0.6486 - acc: 0.6347 - val_loss: 0.6459 - val_acc: 0.6398\n",
      "Epoch 62/200\n",
      "38528/38678 [============================>.] - ETA: 0s - loss: 0.6496 - acc: 0.6315Epoch 00061: val_loss did not improve\n",
      "38678/38678 [==============================] - 10s - loss: 0.6496 - acc: 0.6315 - val_loss: 0.6464 - val_acc: 0.6401\n",
      "Epoch 63/200\n",
      "38656/38678 [============================>.] - ETA: 0s - loss: 0.6487 - acc: 0.6333- ETAEpoch 00062: val_loss improved from 0.64566 to 0.64552, saving model to weights_filter.hdf5\n",
      "38678/38678 [==============================] - 12s - loss: 0.6486 - acc: 0.6333 - val_loss: 0.6455 - val_acc: 0.6401\n",
      "Epoch 64/200\n",
      "38656/38678 [============================>.] - ETA: 0s - loss: 0.6485 - acc: 0.6321Epoch 00063: val_loss did not improve\n",
      "38678/38678 [==============================] - 15s - loss: 0.6486 - acc: 0.6321 - val_loss: 0.6457 - val_acc: 0.6408\n",
      "Epoch 65/200\n",
      "38656/38678 [============================>.] - ETA: 0s - loss: 0.6485 - acc: 0.6327Epoch 00064: val_loss did not improve\n",
      "38678/38678 [==============================] - 16s - loss: 0.6485 - acc: 0.6327 - val_loss: 0.6464 - val_acc: 0.6405\n",
      "Epoch 66/200\n",
      "38592/38678 [============================>.] - ETA: 0s - loss: 0.6483 - acc: 0.6349Epoch 00065: val_loss did not improve\n",
      "38678/38678 [==============================] - 16s - loss: 0.6483 - acc: 0.6350 - val_loss: 0.6459 - val_acc: 0.6391\n",
      "Epoch 67/200\n",
      "38656/38678 [============================>.] - ETA: 0s - loss: 0.6474 - acc: 0.6353Epoch 00066: val_loss improved from 0.64552 to 0.64545, saving model to weights_filter.hdf5\n",
      "38678/38678 [==============================] - 15s - loss: 0.6474 - acc: 0.6353 - val_loss: 0.6455 - val_acc: 0.6398\n",
      "Epoch 68/200\n",
      "38592/38678 [============================>.] - ETA: 0s - loss: 0.6486 - acc: 0.6340Epoch 00067: val_loss improved from 0.64545 to 0.64514, saving model to weights_filter.hdf5\n",
      "38678/38678 [==============================] - 9s - loss: 0.6484 - acc: 0.6344 - val_loss: 0.6451 - val_acc: 0.6398\n",
      "Epoch 69/200\n",
      "38656/38678 [============================>.] - ETA: 0s - loss: 0.6482 - acc: 0.6336Epoch 00068: val_loss did not improve\n",
      "38678/38678 [==============================] - 11s - loss: 0.6482 - acc: 0.6337 - val_loss: 0.6463 - val_acc: 0.6382\n",
      "Epoch 70/200\n",
      "38528/38678 [============================>.] - ETA: 0s - loss: 0.6476 - acc: 0.6336Epoch 00069: val_loss did not improve\n",
      "38678/38678 [==============================] - 15s - loss: 0.6476 - acc: 0.6337 - val_loss: 0.6452 - val_acc: 0.6398\n",
      "Epoch 71/200\n",
      "38656/38678 [============================>.] - ETA: 0s - loss: 0.6470 - acc: 0.6355Epoch 00070: val_loss did not improve\n",
      "38678/38678 [==============================] - 16s - loss: 0.6471 - acc: 0.6353 - val_loss: 0.6457 - val_acc: 0.6398\n",
      "Epoch 72/200\n",
      "38656/38678 [============================>.] - ETA: 0s - loss: 0.6475 - acc: 0.6338Epoch 00071: val_loss did not improve\n",
      "38678/38678 [==============================] - 16s - loss: 0.6475 - acc: 0.6338 - val_loss: 0.6453 - val_acc: 0.6398\n",
      "Epoch 73/200\n",
      "38528/38678 [============================>.] - ETA: 0s - loss: 0.6478 - acc: 0.6320Epoch 00072: val_loss did not improve\n",
      "38678/38678 [==============================] - 16s - loss: 0.6477 - acc: 0.6322 - val_loss: 0.6454 - val_acc: 0.6396\n",
      "Epoch 74/200\n",
      "38656/38678 [============================>.] - ETA: 0s - loss: 0.6473 - acc: 0.6358Epoch 00073: val_loss did not improve\n",
      "38678/38678 [==============================] - 10s - loss: 0.6473 - acc: 0.6358 - val_loss: 0.6454 - val_acc: 0.6398\n",
      "Epoch 75/200\n",
      "38656/38678 [============================>.] - ETA: 0s - loss: 0.6467 - acc: 0.6335Epoch 00074: val_loss improved from 0.64514 to 0.64495, saving model to weights_filter.hdf5\n",
      "38678/38678 [==============================] - 10s - loss: 0.6467 - acc: 0.6335 - val_loss: 0.6449 - val_acc: 0.6401\n",
      "Epoch 76/200\n",
      "38656/38678 [============================>.] - ETA: 0s - loss: 0.6468 - acc: 0.6370Epoch 00075: val_loss did not improve\n",
      "38678/38678 [==============================] - 15s - loss: 0.6468 - acc: 0.6369 - val_loss: 0.6464 - val_acc: 0.6403\n",
      "Epoch 77/200\n",
      "38592/38678 [============================>.] - ETA: 0s - loss: 0.6465 - acc: 0.6368Epoch 00076: val_loss did not improve\n",
      "38678/38678 [==============================] - 16s - loss: 0.6463 - acc: 0.6371 - val_loss: 0.6451 - val_acc: 0.6403\n",
      "Epoch 78/200\n",
      "38656/38678 [============================>.] - ETA: 0s - loss: 0.6474 - acc: 0.6340Epoch 00077: val_loss did not improve\n",
      "38678/38678 [==============================] - 16s - loss: 0.6474 - acc: 0.6340 - val_loss: 0.6452 - val_acc: 0.6403\n",
      "Epoch 79/200\n",
      "38656/38678 [============================>.] - ETA: 0s - loss: 0.6470 - acc: 0.6348Epoch 00078: val_loss did not improve\n",
      "38678/38678 [==============================] - 16s - loss: 0.6471 - acc: 0.6348 - val_loss: 0.6454 - val_acc: 0.6401\n",
      "Epoch 80/200\n",
      "38592/38678 [============================>.] - ETA: 0s - loss: 0.6473 - acc: 0.6352Epoch 00079: val_loss did not improve\n",
      "38678/38678 [==============================] - 12s - loss: 0.6474 - acc: 0.6350 - val_loss: 0.6462 - val_acc: 0.6384\n",
      "Epoch 81/200\n",
      "38592/38678 [============================>.] - ETA: 0s - loss: 0.6469 - acc: 0.6343Epoch 00080: val_loss did not improve\n",
      "38678/38678 [==============================] - 10s - loss: 0.6467 - acc: 0.6346 - val_loss: 0.6459 - val_acc: 0.6380\n",
      "Epoch 82/200\n",
      "38656/38678 [============================>.] - ETA: 0s - loss: 0.6465 - acc: 0.6342Epoch 00081: val_loss improved from 0.64495 to 0.64484, saving model to weights_filter.hdf5\n",
      "38678/38678 [==============================] - 14s - loss: 0.6465 - acc: 0.6342 - val_loss: 0.6448 - val_acc: 0.6398\n",
      "Epoch 83/200\n",
      "38656/38678 [============================>.] - ETA: 0s - loss: 0.6473 - acc: 0.6328Epoch 00082: val_loss did not improve\n",
      "38678/38678 [==============================] - 16s - loss: 0.6472 - acc: 0.6329 - val_loss: 0.6459 - val_acc: 0.6401\n",
      "Epoch 84/200\n",
      "38656/38678 [============================>.] - ETA: 0s - loss: 0.6482 - acc: 0.6351Epoch 00083: val_loss did not improve\n",
      "38678/38678 [==============================] - 16s - loss: 0.6481 - acc: 0.6351 - val_loss: 0.6449 - val_acc: 0.6401\n",
      "Epoch 85/200\n",
      "38592/38678 [============================>.] - ETA: 0s - loss: 0.6476 - acc: 0.6346Epoch 00084: val_loss did not improve\n",
      "38678/38678 [==============================] - 16s - loss: 0.6476 - acc: 0.6345 - val_loss: 0.6453 - val_acc: 0.6398\n",
      "Epoch 86/200\n",
      "38592/38678 [============================>.] - ETA: 0s - loss: 0.6470 - acc: 0.6353Epoch 00085: val_loss did not improve\n",
      "38678/38678 [==============================] - 14s - loss: 0.6471 - acc: 0.6353 - val_loss: 0.6456 - val_acc: 0.6391\n",
      "Epoch 87/200\n",
      "38656/38678 [============================>.] - ETA: 0s - loss: 0.6471 - acc: 0.6348Epoch 00086: val_loss did not improve\n",
      "38678/38678 [==============================] - 10s - loss: 0.6471 - acc: 0.6347 - val_loss: 0.6452 - val_acc: 0.6401\n",
      "Epoch 88/200\n",
      "38656/38678 [============================>.] - ETA: 0s - loss: 0.6477 - acc: 0.6351Epoch 00087: val_loss did not improve\n",
      "38678/38678 [==============================] - 12s - loss: 0.6477 - acc: 0.6350 - val_loss: 0.6451 - val_acc: 0.6398\n",
      "Epoch 89/200\n",
      "38592/38678 [============================>.] - ETA: 0s - loss: 0.6463 - acc: 0.6359Epoch 00088: val_loss did not improve\n",
      "38678/38678 [==============================] - 16s - loss: 0.6463 - acc: 0.6359 - val_loss: 0.6450 - val_acc: 0.6396\n",
      "Epoch 90/200\n",
      "38592/38678 [============================>.] - ETA: 0s - loss: 0.6474 - acc: 0.6326Epoch 00089: val_loss did not improve\n",
      "38678/38678 [==============================] - 16s - loss: 0.6474 - acc: 0.6326 - val_loss: 0.6459 - val_acc: 0.6398\n",
      "Epoch 91/200\n",
      "38528/38678 [============================>.] - ETA: 0s - loss: 0.6474 - acc: 0.6328Epoch 00090: val_loss improved from 0.64484 to 0.64482, saving model to weights_filter.hdf5\n",
      "38678/38678 [==============================] - 16s - loss: 0.6473 - acc: 0.6330 - val_loss: 0.6448 - val_acc: 0.6403\n",
      "Epoch 92/200\n",
      "38528/38678 [============================>.] - ETA: 0s - loss: 0.6466 - acc: 0.6352Epoch 00091: val_loss did not improve\n",
      "38678/38678 [==============================] - 16s - loss: 0.6466 - acc: 0.6353 - val_loss: 0.6463 - val_acc: 0.6403\n",
      "Epoch 93/200\n",
      "38528/38678 [============================>.] - ETA: 0s - loss: 0.6477 - acc: 0.6342Epoch 00092: val_loss did not improve\n",
      "38678/38678 [==============================] - 10s - loss: 0.6476 - acc: 0.6344 - val_loss: 0.6456 - val_acc: 0.6403\n",
      "Epoch 94/200\n",
      "38464/38678 [============================>.] - ETA: 0s - loss: 0.6467 - acc: 0.6364Epoch 00093: val_loss did not improve\n",
      "38678/38678 [==============================] - 10s - loss: 0.6468 - acc: 0.6364 - val_loss: 0.6451 - val_acc: 0.6398\n",
      "Epoch 95/200\n",
      "38656/38678 [============================>.] - ETA: 0s - loss: 0.6470 - acc: 0.6347Epoch 00094: val_loss did not improve\n",
      "38678/38678 [==============================] - 15s - loss: 0.6469 - acc: 0.6347 - val_loss: 0.6449 - val_acc: 0.6403\n",
      "Epoch 96/200\n",
      "38656/38678 [============================>.] - ETA: 0s - loss: 0.6465 - acc: 0.6369Epoch 00095: val_loss improved from 0.64482 to 0.64480, saving model to weights_filter.hdf5\n",
      "38678/38678 [==============================] - 16s - loss: 0.6465 - acc: 0.6370 - val_loss: 0.6448 - val_acc: 0.6401\n",
      "Epoch 97/200\n",
      "38592/38678 [============================>.] - ETA: 0s - loss: 0.6465 - acc: 0.6354Epoch 00096: val_loss did not improve\n",
      "38678/38678 [==============================] - 16s - loss: 0.6465 - acc: 0.6355 - val_loss: 0.6449 - val_acc: 0.6401\n",
      "Epoch 98/200\n",
      "38656/38678 [============================>.] - ETA: 0s - loss: 0.6461 - acc: 0.6358Epoch 00097: val_loss did not improve\n",
      "38678/38678 [==============================] - 16s - loss: 0.6461 - acc: 0.6357 - val_loss: 0.6454 - val_acc: 0.6403\n",
      "Epoch 99/200\n",
      "38528/38678 [============================>.] - ETA: 0s - loss: 0.6471 - acc: 0.6352Epoch 00098: val_loss did not improve\n",
      "38678/38678 [==============================] - 12s - loss: 0.6471 - acc: 0.6353 - val_loss: 0.6449 - val_acc: 0.6401\n",
      "Epoch 100/200\n",
      "38656/38678 [============================>.] - ETA: 0s - loss: 0.6461 - acc: 0.6362Epoch 00099: val_loss did not improve\n",
      "38678/38678 [==============================] - 10s - loss: 0.6460 - acc: 0.6362 - val_loss: 0.6449 - val_acc: 0.6396\n",
      "Epoch 101/200\n",
      "38592/38678 [============================>.] - ETA: 0s - loss: 0.6480 - acc: 0.6334Epoch 00100: val_loss did not improve\n",
      "38678/38678 [==============================] - 14s - loss: 0.6479 - acc: 0.6335 - val_loss: 0.6450 - val_acc: 0.6403\n",
      "Epoch 102/200\n",
      "38592/38678 [============================>.] - ETA: 0s - loss: 0.6467 - acc: 0.6347Epoch 00101: val_loss did not improve\n",
      "38678/38678 [==============================] - 16s - loss: 0.6467 - acc: 0.6348 - val_loss: 0.6454 - val_acc: 0.6403\n",
      "Epoch 103/200\n",
      "38592/38678 [============================>.] - ETA: 0s - loss: 0.6467 - acc: 0.6349Epoch 00102: val_loss improved from 0.64480 to 0.64459, saving model to weights_filter.hdf5\n",
      "38678/38678 [==============================] - 16s - loss: 0.6467 - acc: 0.6348 - val_loss: 0.6446 - val_acc: 0.6405\n",
      "Epoch 104/200\n",
      "38592/38678 [============================>.] - ETA: 0s - loss: 0.6462 - acc: 0.6360Epoch 00103: val_loss did not improve\n",
      "38678/38678 [==============================] - 16s - loss: 0.6463 - acc: 0.6359 - val_loss: 0.6462 - val_acc: 0.6387\n",
      "Epoch 105/200\n",
      "38528/38678 [============================>.] - ETA: 0s - loss: 0.6473 - acc: 0.6336Epoch 00104: val_loss did not improve\n",
      "38678/38678 [==============================] - 13s - loss: 0.6474 - acc: 0.6335 - val_loss: 0.6446 - val_acc: 0.6408\n",
      "Epoch 106/200\n",
      "38656/38678 [============================>.] - ETA: 0s - loss: 0.6459 - acc: 0.6368Epoch 00105: val_loss did not improve\n",
      "38678/38678 [==============================] - 10s - loss: 0.6460 - acc: 0.6367 - val_loss: 0.6451 - val_acc: 0.6384\n",
      "Epoch 107/200\n",
      "38656/38678 [============================>.] - ETA: 0s - loss: 0.6468 - acc: 0.6351Epoch 00106: val_loss did not improve\n",
      "38678/38678 [==============================] - 13s - loss: 0.6468 - acc: 0.6350 - val_loss: 0.6453 - val_acc: 0.6403\n",
      "Epoch 108/200\n",
      "38656/38678 [============================>.] - ETA: 0s - loss: 0.6474 - acc: 0.6346Epoch 00107: val_loss did not improve\n",
      "38678/38678 [==============================] - 16s - loss: 0.6473 - acc: 0.6348 - val_loss: 0.6455 - val_acc: 0.6384\n",
      "Epoch 109/200\n",
      "38592/38678 [============================>.] - ETA: 0s - loss: 0.6465 - acc: 0.6347Epoch 00108: val_loss did not improve\n",
      "38678/38678 [==============================] - 16s - loss: 0.6466 - acc: 0.6347 - val_loss: 0.6447 - val_acc: 0.6408\n",
      "Epoch 110/200\n",
      "38592/38678 [============================>.] - ETA: 0s - loss: 0.6472 - acc: 0.6317Epoch 00109: val_loss did not improve\n",
      "38678/38678 [==============================] - 16s - loss: 0.6471 - acc: 0.6319 - val_loss: 0.6446 - val_acc: 0.6401\n",
      "Epoch 111/200\n",
      "38528/38678 [============================>.] - ETA: 0s - loss: 0.6458 - acc: 0.6355Epoch 00110: val_loss did not improve\n",
      "38678/38678 [==============================] - 15s - loss: 0.6458 - acc: 0.6355 - val_loss: 0.6447 - val_acc: 0.6403\n",
      "Epoch 112/200\n",
      "38592/38678 [============================>.] - ETA: 0s - loss: 0.6460 - acc: 0.6355Epoch 00111: val_loss did not improve\n",
      "38678/38678 [==============================] - 9s - loss: 0.6459 - acc: 0.6358 - val_loss: 0.6457 - val_acc: 0.6403\n",
      "Epoch 113/200\n",
      "38592/38678 [============================>.] - ETA: 0s - loss: 0.6473 - acc: 0.6346Epoch 00112: val_loss did not improve\n",
      "38678/38678 [==============================] - 10s - loss: 0.6473 - acc: 0.6347 - val_loss: 0.6462 - val_acc: 0.6403\n",
      "Epoch 114/200\n",
      "38592/38678 [============================>.] - ETA: 0s - loss: 0.6468 - acc: 0.6342Epoch 00113: val_loss did not improve\n",
      "38678/38678 [==============================] - 15s - loss: 0.6468 - acc: 0.6342 - val_loss: 0.6457 - val_acc: 0.6380\n",
      "Epoch 115/200\n",
      "38656/38678 [============================>.] - ETA: 0s - loss: 0.6472 - acc: 0.6356Epoch 00114: val_loss did not improve\n",
      "38678/38678 [==============================] - 16s - loss: 0.6472 - acc: 0.6357 - val_loss: 0.6449 - val_acc: 0.6401\n",
      "Epoch 116/200\n",
      "38528/38678 [============================>.] - ETA: 0s - loss: 0.6459 - acc: 0.6385Epoch 00115: val_loss improved from 0.64459 to 0.64432, saving model to weights_filter.hdf5\n",
      "38678/38678 [==============================] - 16s - loss: 0.6459 - acc: 0.6387 - val_loss: 0.6443 - val_acc: 0.6408\n",
      "Epoch 117/200\n",
      "38656/38678 [============================>.] - ETA: 0s - loss: 0.6460 - acc: 0.6365Epoch 00116: val_loss did not improve\n",
      "38678/38678 [==============================] - 16s - loss: 0.6461 - acc: 0.6364 - val_loss: 0.6458 - val_acc: 0.6401\n",
      "Epoch 118/200\n",
      "38656/38678 [============================>.] - ETA: 0s - loss: 0.6460 - acc: 0.6351Epoch 00117: val_loss did not improve\n",
      "38678/38678 [==============================] - 11s - loss: 0.6460 - acc: 0.6351 - val_loss: 0.6449 - val_acc: 0.6405\n",
      "Epoch 119/200\n",
      "38656/38678 [============================>.] - ETA: 0s - loss: 0.6466 - acc: 0.6371Epoch 00118: val_loss did not improve\n",
      "38678/38678 [==============================] - 10s - loss: 0.6465 - acc: 0.6372 - val_loss: 0.6458 - val_acc: 0.6401\n",
      "Epoch 120/200\n",
      "38656/38678 [============================>.] - ETA: 0s - loss: 0.6462 - acc: 0.6343Epoch 00119: val_loss did not improve\n",
      "38678/38678 [==============================] - 15s - loss: 0.6462 - acc: 0.6343 - val_loss: 0.6444 - val_acc: 0.6410\n",
      "Epoch 121/200\n",
      "38656/38678 [============================>.] - ETA: 0s - loss: 0.6465 - acc: 0.6360Epoch 00120: val_loss did not improve\n",
      "38678/38678 [==============================] - 16s - loss: 0.6466 - acc: 0.6360 - val_loss: 0.6450 - val_acc: 0.6401\n",
      "Epoch 122/200\n",
      "38592/38678 [============================>.] - ETA: 0s - loss: 0.6457 - acc: 0.6352Epoch 00121: val_loss did not improve\n",
      "38678/38678 [==============================] - 16s - loss: 0.6457 - acc: 0.6352 - val_loss: 0.6448 - val_acc: 0.6401\n",
      "Epoch 123/200\n",
      "38528/38678 [============================>.] - ETA: 0s - loss: 0.6468 - acc: 0.6358Epoch 00122: val_loss did not improve\n",
      "38678/38678 [==============================] - 16s - loss: 0.6467 - acc: 0.6360 - val_loss: 0.6443 - val_acc: 0.6405\n",
      "Epoch 124/200\n",
      "38656/38678 [============================>.] - ETA: 0s - loss: 0.6474 - acc: 0.6331Epoch 00123: val_loss did not improve\n",
      "38678/38678 [==============================] - 13s - loss: 0.6475 - acc: 0.6329 - val_loss: 0.6450 - val_acc: 0.6408\n",
      "Epoch 125/200\n",
      "38592/38678 [============================>.] - ETA: 0s - loss: 0.6459 - acc: 0.6347Epoch 00124: val_loss did not improve\n",
      "38678/38678 [==============================] - 9s - loss: 0.6458 - acc: 0.6347 - val_loss: 0.6452 - val_acc: 0.6405\n",
      "Epoch 126/200\n",
      "38656/38678 [============================>.] - ETA: 0s - loss: 0.6464 - acc: 0.6333Epoch 00125: val_loss did not improve\n",
      "38678/38678 [==============================] - 13s - loss: 0.6463 - acc: 0.6334 - val_loss: 0.6447 - val_acc: 0.6405\n",
      "Epoch 127/200\n",
      "38656/38678 [============================>.] - ETA: 0s - loss: 0.6451 - acc: 0.6354Epoch 00126: val_loss did not improve\n",
      "38678/38678 [==============================] - 15s - loss: 0.6451 - acc: 0.6353 - val_loss: 0.6454 - val_acc: 0.6405\n",
      "Epoch 128/200\n",
      "38592/38678 [============================>.] - ETA: 0s - loss: 0.6467 - acc: 0.6363Epoch 00127: val_loss did not improve\n",
      "38678/38678 [==============================] - 16s - loss: 0.6468 - acc: 0.6363 - val_loss: 0.6452 - val_acc: 0.6405\n",
      "Epoch 129/200\n",
      "38592/38678 [============================>.] - ETA: 0s - loss: 0.6460 - acc: 0.6348Epoch 00128: val_loss did not improve\n",
      "38678/38678 [==============================] - 16s - loss: 0.6460 - acc: 0.6349 - val_loss: 0.6453 - val_acc: 0.6403\n",
      "Epoch 130/200\n",
      "38464/38678 [============================>.] - ETA: 0s - loss: 0.6460 - acc: 0.6341Epoch 00129: val_loss did not improve\n",
      "38678/38678 [==============================] - 15s - loss: 0.6462 - acc: 0.6337 - val_loss: 0.6448 - val_acc: 0.6408\n",
      "Epoch 131/200\n",
      "38656/38678 [============================>.] - ETA: 0s - loss: 0.6463 - acc: 0.6372Epoch 00130: val_loss did not improve\n",
      "38678/38678 [==============================] - 9s - loss: 0.6463 - acc: 0.6373 - val_loss: 0.6456 - val_acc: 0.6398\n",
      "Epoch 132/200\n",
      "38528/38678 [============================>.] - ETA: 0s - loss: 0.6469 - acc: 0.6358Epoch 00131: val_loss did not improve\n",
      "38678/38678 [==============================] - 10s - loss: 0.6468 - acc: 0.6360 - val_loss: 0.6446 - val_acc: 0.6403\n",
      "Epoch 133/200\n",
      "38528/38678 [============================>.] - ETA: 0s - loss: 0.6465 - acc: 0.6336Epoch 00132: val_loss did not improve\n",
      "38678/38678 [==============================] - 15s - loss: 0.6464 - acc: 0.6336 - val_loss: 0.6455 - val_acc: 0.6317\n",
      "Epoch 134/200\n",
      "38528/38678 [============================>.] - ETA: 0s - loss: 0.6461 - acc: 0.6368Epoch 00133: val_loss did not improve\n",
      "38678/38678 [==============================] - 15s - loss: 0.6460 - acc: 0.6370 - val_loss: 0.6445 - val_acc: 0.6405\n",
      "Epoch 135/200\n",
      "38592/38678 [============================>.] - ETA: 0s - loss: 0.6460 - acc: 0.6353Epoch 00134: val_loss did not improve\n",
      "38678/38678 [==============================] - 15s - loss: 0.6460 - acc: 0.6353 - val_loss: 0.6452 - val_acc: 0.6405\n",
      "Epoch 136/200\n",
      "38592/38678 [============================>.] - ETA: 0s - loss: 0.6467 - acc: 0.6361Epoch 00135: val_loss did not improve\n",
      "38678/38678 [==============================] - 15s - loss: 0.6467 - acc: 0.6361 - val_loss: 0.6446 - val_acc: 0.6410\n",
      "Epoch 137/200\n",
      "38464/38678 [============================>.] - ETA: 0s - loss: 0.6459 - acc: 0.6355Epoch 00136: val_loss did not improve\n",
      "38678/38678 [==============================] - 12s - loss: 0.6461 - acc: 0.6353 - val_loss: 0.6463 - val_acc: 0.6384\n",
      "Epoch 138/200\n",
      "38656/38678 [============================>.] - ETA: 0s - loss: 0.6465 - acc: 0.6352Epoch 00137: val_loss did not improve\n",
      "38678/38678 [==============================] - 9s - loss: 0.6465 - acc: 0.6352 - val_loss: 0.6450 - val_acc: 0.6405\n",
      "Epoch 139/200\n",
      "38656/38678 [============================>.] - ETA: 0s - loss: 0.6459 - acc: 0.6353Epoch 00138: val_loss did not improve\n",
      "38678/38678 [==============================] - 14s - loss: 0.6459 - acc: 0.6353 - val_loss: 0.6457 - val_acc: 0.6398\n",
      "Epoch 140/200\n",
      "38656/38678 [============================>.] - ETA: 0s - loss: 0.6459 - acc: 0.6368Epoch 00139: val_loss did not improve\n",
      "38678/38678 [==============================] - 15s - loss: 0.6458 - acc: 0.6370 - val_loss: 0.6446 - val_acc: 0.6408\n",
      "Epoch 141/200\n",
      "38656/38678 [============================>.] - ETA: 0s - loss: 0.6467 - acc: 0.6349Epoch 00140: val_loss did not improve\n",
      "38678/38678 [==============================] - 16s - loss: 0.6467 - acc: 0.6348 - val_loss: 0.6462 - val_acc: 0.6387\n",
      "Epoch 142/200\n",
      "38592/38678 [============================>.] - ETA: 0s - loss: 0.6455 - acc: 0.6366Epoch 00141: val_loss did not improve\n",
      "38678/38678 [==============================] - 15s - loss: 0.6455 - acc: 0.6367 - val_loss: 0.6447 - val_acc: 0.6391\n",
      "Epoch 143/200\n",
      "38464/38678 [============================>.] - ETA: 0s - loss: 0.6454 - acc: 0.6359Epoch 00142: val_loss did not improve\n",
      "38678/38678 [==============================] - 13s - loss: 0.6455 - acc: 0.6358 - val_loss: 0.6451 - val_acc: 0.6394\n",
      "Epoch 144/200\n",
      "38464/38678 [============================>.] - ETA: 0s - loss: 0.6453 - acc: 0.6359Epoch 00143: val_loss did not improve\n",
      "38678/38678 [==============================] - 9s - loss: 0.6452 - acc: 0.6359 - val_loss: 0.6448 - val_acc: 0.6408\n",
      "Epoch 145/200\n",
      "38656/38678 [============================>.] - ETA: 0s - loss: 0.6458 - acc: 0.6366Epoch 00144: val_loss did not improve\n",
      "38678/38678 [==============================] - 11s - loss: 0.6457 - acc: 0.6367 - val_loss: 0.6448 - val_acc: 0.6403\n",
      "Epoch 146/200\n",
      "38528/38678 [============================>.] - ETA: 0s - loss: 0.6468 - acc: 0.6340Epoch 00145: val_loss did not improve\n",
      "38678/38678 [==============================] - 15s - loss: 0.6468 - acc: 0.6341 - val_loss: 0.6445 - val_acc: 0.6401\n",
      "Epoch 147/200\n",
      "38592/38678 [============================>.] - ETA: 0s - loss: 0.6459 - acc: 0.6360Epoch 00146: val_loss did not improve\n",
      "38678/38678 [==============================] - 15s - loss: 0.6459 - acc: 0.6359 - val_loss: 0.6445 - val_acc: 0.6405\n",
      "Epoch 148/200\n",
      "38656/38678 [============================>.] - ETA: 0s - loss: 0.6467 - acc: 0.6332Epoch 00147: val_loss did not improve\n",
      "38678/38678 [==============================] - 15s - loss: 0.6468 - acc: 0.6332 - val_loss: 0.6451 - val_acc: 0.6410\n",
      "Epoch 149/200\n",
      "38528/38678 [============================>.] - ETA: 0s - loss: 0.6458 - acc: 0.6364Epoch 00148: val_loss did not improve\n",
      "38678/38678 [==============================] - 15s - loss: 0.6458 - acc: 0.6363 - val_loss: 0.6448 - val_acc: 0.6389\n",
      "Epoch 150/200\n",
      "38464/38678 [============================>.] - ETA: 0s - loss: 0.6460 - acc: 0.6365Epoch 00149: val_loss did not improve\n",
      "38678/38678 [==============================] - 10s - loss: 0.6460 - acc: 0.6365 - val_loss: 0.6446 - val_acc: 0.6396\n",
      "Epoch 151/200\n",
      "38464/38678 [============================>.] - ETA: 0s - loss: 0.6463 - acc: 0.6365Epoch 00150: val_loss did not improve\n",
      "38678/38678 [==============================] - 9s - loss: 0.6462 - acc: 0.6370 - val_loss: 0.6454 - val_acc: 0.6405\n",
      "Epoch 152/200\n",
      "38592/38678 [============================>.] - ETA: 0s - loss: 0.6457 - acc: 0.6363Epoch 00151: val_loss did not improve\n",
      "38678/38678 [==============================] - 14s - loss: 0.6459 - acc: 0.6361 - val_loss: 0.6451 - val_acc: 0.6394\n",
      "Epoch 153/200\n",
      "38656/38678 [============================>.] - ETA: 0s - loss: 0.6461 - acc: 0.6361Epoch 00152: val_loss did not improve\n",
      "38678/38678 [==============================] - 15s - loss: 0.6461 - acc: 0.6361 - val_loss: 0.6449 - val_acc: 0.6396\n",
      "Epoch 154/200\n",
      "38656/38678 [============================>.] - ETA: 0s - loss: 0.6462 - acc: 0.6357Epoch 00153: val_loss did not improve\n",
      "38678/38678 [==============================] - 16s - loss: 0.6463 - acc: 0.6357 - val_loss: 0.6452 - val_acc: 0.6403\n",
      "Epoch 155/200\n",
      "38528/38678 [============================>.] - ETA: 0s - loss: 0.6459 - acc: 0.6353Epoch 00154: val_loss did not improve\n",
      "38678/38678 [==============================] - 16s - loss: 0.6459 - acc: 0.6351 - val_loss: 0.6448 - val_acc: 0.6405\n",
      "Epoch 156/200\n",
      "38528/38678 [============================>.] - ETA: 0s - loss: 0.6467 - acc: 0.6349Epoch 00155: val_loss improved from 0.64432 to 0.64423, saving model to weights_filter.hdf5\n",
      "38678/38678 [==============================] - 13s - loss: 0.6466 - acc: 0.6350 - val_loss: 0.6442 - val_acc: 0.6401\n",
      "Epoch 157/200\n",
      "38528/38678 [============================>.] - ETA: 0s - loss: 0.6460 - acc: 0.6352Epoch 00156: val_loss did not improve\n",
      "38678/38678 [==============================] - 9s - loss: 0.6460 - acc: 0.6353 - val_loss: 0.6444 - val_acc: 0.6410\n",
      "Epoch 158/200\n",
      "38592/38678 [============================>.] - ETA: 0s - loss: 0.6456 - acc: 0.6352Epoch 00157: val_loss did not improve\n",
      "38678/38678 [==============================] - 12s - loss: 0.6456 - acc: 0.6352 - val_loss: 0.6446 - val_acc: 0.6405\n",
      "Epoch 159/200\n",
      "38592/38678 [============================>.] - ETA: 0s - loss: 0.6462 - acc: 0.6351Epoch 00158: val_loss did not improve\n",
      "38678/38678 [==============================] - 15s - loss: 0.6463 - acc: 0.6351 - val_loss: 0.6450 - val_acc: 0.6394\n",
      "Epoch 160/200\n",
      "38656/38678 [============================>.] - ETA: 0s - loss: 0.6453 - acc: 0.6375Epoch 00159: val_loss did not improve\n",
      "38678/38678 [==============================] - 15s - loss: 0.6454 - acc: 0.6375 - val_loss: 0.6445 - val_acc: 0.6403\n",
      "Epoch 161/200\n",
      "38592/38678 [============================>.] - ETA: 0s - loss: 0.6463 - acc: 0.6373Epoch 00160: val_loss did not improve\n",
      "38678/38678 [==============================] - 15s - loss: 0.6463 - acc: 0.6373 - val_loss: 0.6448 - val_acc: 0.6403\n",
      "Epoch 162/200\n",
      "38656/38678 [============================>.] - ETA: 0s - loss: 0.6461 - acc: 0.6361Epoch 00161: val_loss did not improve\n",
      "38678/38678 [==============================] - 15s - loss: 0.6461 - acc: 0.6360 - val_loss: 0.6444 - val_acc: 0.6398\n",
      "Epoch 163/200\n",
      "38592/38678 [============================>.] - ETA: 0s - loss: 0.6467 - acc: 0.6353Epoch 00162: val_loss did not improve\n",
      "38678/38678 [==============================] - 9s - loss: 0.6466 - acc: 0.6355 - val_loss: 0.6444 - val_acc: 0.6394\n",
      "Epoch 164/200\n",
      "38464/38678 [============================>.] - ETA: 0s - loss: 0.6461 - acc: 0.6344Epoch 00163: val_loss did not improve\n",
      "38678/38678 [==============================] - 9s - loss: 0.6462 - acc: 0.6344 - val_loss: 0.6445 - val_acc: 0.6408\n",
      "Epoch 165/200\n",
      "38592/38678 [============================>.] - ETA: 0s - loss: 0.6464 - acc: 0.6352Epoch 00164: val_loss did not improve\n",
      "38678/38678 [==============================] - 15s - loss: 0.6463 - acc: 0.6354 - val_loss: 0.6444 - val_acc: 0.6398\n",
      "Epoch 166/200\n",
      "38528/38678 [============================>.] - ETA: 0s - loss: 0.6469 - acc: 0.6334Epoch 00165: val_loss did not improve\n",
      "38678/38678 [==============================] - 15s - loss: 0.6469 - acc: 0.6335 - val_loss: 0.6446 - val_acc: 0.6403\n",
      "Epoch 167/200\n",
      "38656/38678 [============================>.] - ETA: 0s - loss: 0.6453 - acc: 0.6375Epoch 00166: val_loss did not improve\n",
      "38678/38678 [==============================] - 15s - loss: 0.6453 - acc: 0.6375 - val_loss: 0.6448 - val_acc: 0.6408\n",
      "Epoch 168/200\n",
      "38528/38678 [============================>.] - ETA: 0s - loss: 0.6457 - acc: 0.6363Epoch 00167: val_loss did not improve\n",
      "38678/38678 [==============================] - 15s - loss: 0.6456 - acc: 0.6362 - val_loss: 0.6455 - val_acc: 0.6387\n",
      "Epoch 169/200\n",
      "38592/38678 [============================>.] - ETA: 0s - loss: 0.6459 - acc: 0.6353Epoch 00168: val_loss did not improve\n",
      "38678/38678 [==============================] - 12s - loss: 0.6458 - acc: 0.6354 - val_loss: 0.6449 - val_acc: 0.6380\n",
      "Epoch 170/200\n",
      "38656/38678 [============================>.] - ETA: 0s - loss: 0.6459 - acc: 0.6345Epoch 00169: val_loss did not improve\n",
      "38678/38678 [==============================] - 9s - loss: 0.6459 - acc: 0.6345 - val_loss: 0.6449 - val_acc: 0.6403\n",
      "Epoch 171/200\n",
      "38592/38678 [============================>.] - ETA: 0s - loss: 0.6456 - acc: 0.6367Epoch 00170: val_loss improved from 0.64423 to 0.64422, saving model to weights_filter.hdf5\n",
      "38678/38678 [==============================] - 11s - loss: 0.6456 - acc: 0.6367 - val_loss: 0.6442 - val_acc: 0.6398\n",
      "Epoch 172/200\n",
      "38656/38678 [============================>.] - ETA: 0s - loss: 0.6468 - acc: 0.6355Epoch 00171: val_loss did not improve\n",
      "38678/38678 [==============================] - 15s - loss: 0.6468 - acc: 0.6355 - val_loss: 0.6444 - val_acc: 0.6394\n",
      "Epoch 173/200\n",
      "38592/38678 [============================>.] - ETA: 0s - loss: 0.6457 - acc: 0.6360Epoch 00172: val_loss did not improve\n",
      "38678/38678 [==============================] - 15s - loss: 0.6458 - acc: 0.6359 - val_loss: 0.6446 - val_acc: 0.6405\n",
      "Epoch 174/200\n",
      "38656/38678 [============================>.] - ETA: 0s - loss: 0.6465 - acc: 0.6351Epoch 00173: val_loss did not improve\n",
      "38678/38678 [==============================] - 15s - loss: 0.6465 - acc: 0.6350 - val_loss: 0.6451 - val_acc: 0.6380\n",
      "Epoch 175/200\n",
      "38656/38678 [============================>.] - ETA: 0s - loss: 0.6462 - acc: 0.6343Epoch 00174: val_loss did not improve\n",
      "38678/38678 [==============================] - 16s - loss: 0.6462 - acc: 0.6343 - val_loss: 0.6449 - val_acc: 0.6401\n",
      "Epoch 176/200\n",
      "38656/38678 [============================>.] - ETA: 0s - loss: 0.6462 - acc: 0.6340Epoch 00175: val_loss did not improve\n",
      "38678/38678 [==============================] - 10s - loss: 0.6462 - acc: 0.6340 - val_loss: 0.6452 - val_acc: 0.6401\n",
      "Epoch 177/200\n",
      "38656/38678 [============================>.] - ETA: 0s - loss: 0.6460 - acc: 0.6370Epoch 00176: val_loss did not improve\n",
      "38678/38678 [==============================] - 10s - loss: 0.6459 - acc: 0.6370 - val_loss: 0.6443 - val_acc: 0.6398\n",
      "Epoch 178/200\n",
      "38528/38678 [============================>.] - ETA: 0s - loss: 0.6460 - acc: 0.6365Epoch 00177: val_loss did not improve\n",
      "38678/38678 [==============================] - 14s - loss: 0.6458 - acc: 0.6366 - val_loss: 0.6450 - val_acc: 0.6401\n",
      "Epoch 179/200\n",
      "38656/38678 [============================>.] - ETA: 0s - loss: 0.6454 - acc: 0.6359Epoch 00178: val_loss did not improve\n",
      "38678/38678 [==============================] - 15s - loss: 0.6454 - acc: 0.6359 - val_loss: 0.6453 - val_acc: 0.6394\n",
      "Epoch 180/200\n",
      "38592/38678 [============================>.] - ETA: 0s - loss: 0.6457 - acc: 0.6382Epoch 00179: val_loss did not improve\n",
      "38678/38678 [==============================] - 15s - loss: 0.6459 - acc: 0.6380 - val_loss: 0.6459 - val_acc: 0.6377\n",
      "Epoch 181/200\n",
      "38528/38678 [============================>.] - ETA: 0s - loss: 0.6448 - acc: 0.6387Epoch 00180: val_loss did not improve\n",
      "38678/38678 [==============================] - 16s - loss: 0.6449 - acc: 0.6387 - val_loss: 0.6449 - val_acc: 0.6396\n",
      "Epoch 182/200\n",
      "38656/38678 [============================>.] - ETA: 0s - loss: 0.6459 - acc: 0.6364Epoch 00181: val_loss did not improve\n",
      "38678/38678 [==============================] - 13s - loss: 0.6459 - acc: 0.6363 - val_loss: 0.6444 - val_acc: 0.6401\n",
      "Epoch 183/200\n",
      "38464/38678 [============================>.] - ETA: 0s - loss: 0.6458 - acc: 0.6353Epoch 00182: val_loss did not improve\n",
      "38678/38678 [==============================] - 9s - loss: 0.6458 - acc: 0.6352 - val_loss: 0.6446 - val_acc: 0.6398\n",
      "Epoch 184/200\n",
      "38656/38678 [============================>.] - ETA: 0s - loss: 0.6457 - acc: 0.6352Epoch 00183: val_loss did not improve\n",
      "38678/38678 [==============================] - 11s - loss: 0.6457 - acc: 0.6352 - val_loss: 0.6453 - val_acc: 0.6396\n",
      "Epoch 185/200\n",
      "38592/38678 [============================>.] - ETA: 0s - loss: 0.6460 - acc: 0.6354Epoch 00184: val_loss did not improve\n",
      "38678/38678 [==============================] - 15s - loss: 0.6459 - acc: 0.6356 - val_loss: 0.6444 - val_acc: 0.6401\n",
      "Epoch 186/200\n",
      "38592/38678 [============================>.] - ETA: 0s - loss: 0.6453 - acc: 0.6359Epoch 00185: val_loss did not improve\n",
      "38678/38678 [==============================] - 16s - loss: 0.6454 - acc: 0.6357 - val_loss: 0.6445 - val_acc: 0.6396\n",
      "Epoch 187/200\n",
      "38592/38678 [============================>.] - ETA: 0s - loss: 0.6452 - acc: 0.6376Epoch 00186: val_loss did not improve\n",
      "38678/38678 [==============================] - 16s - loss: 0.6451 - acc: 0.6378 - val_loss: 0.6459 - val_acc: 0.6382\n",
      "Epoch 188/200\n",
      "38656/38678 [============================>.] - ETA: 0s - loss: 0.6458 - acc: 0.6377Epoch 00187: val_loss did not improve\n",
      "38678/38678 [==============================] - 16s - loss: 0.6458 - acc: 0.6376 - val_loss: 0.6470 - val_acc: 0.6156\n",
      "Epoch 189/200\n",
      "38464/38678 [============================>.] - ETA: 0s - loss: 0.6456 - acc: 0.6368Epoch 00188: val_loss improved from 0.64422 to 0.64416, saving model to weights_filter.hdf5\n",
      "38678/38678 [==============================] - 10s - loss: 0.6457 - acc: 0.6367 - val_loss: 0.6442 - val_acc: 0.6405\n",
      "Epoch 190/200\n",
      "38592/38678 [============================>.] - ETA: 0s - loss: 0.6460 - acc: 0.6352Epoch 00189: val_loss did not improve\n",
      "38678/38678 [==============================] - 9s - loss: 0.6459 - acc: 0.6353 - val_loss: 0.6448 - val_acc: 0.6401\n",
      "Epoch 191/200\n",
      "38592/38678 [============================>.] - ETA: 0s - loss: 0.6450 - acc: 0.6384Epoch 00190: val_loss did not improve\n",
      "38678/38678 [==============================] - 15s - loss: 0.6450 - acc: 0.6384 - val_loss: 0.6448 - val_acc: 0.6403\n",
      "Epoch 192/200\n",
      "38656/38678 [============================>.] - ETA: 0s - loss: 0.6465 - acc: 0.6364Epoch 00191: val_loss did not improve\n",
      "38678/38678 [==============================] - 15s - loss: 0.6464 - acc: 0.6365 - val_loss: 0.6458 - val_acc: 0.6405\n",
      "Epoch 193/200\n",
      "38528/38678 [============================>.] - ETA: 0s - loss: 0.6460 - acc: 0.6369Epoch 00192: val_loss did not improve\n",
      "38678/38678 [==============================] - 16s - loss: 0.6460 - acc: 0.6368 - val_loss: 0.6445 - val_acc: 0.6401\n",
      "Epoch 194/200\n",
      "38528/38678 [============================>.] - ETA: 0s - loss: 0.6451 - acc: 0.6364Epoch 00198: val_loss did not improve\n",
      "38678/38678 [==============================] - 15s - loss: 0.6452 - acc: 0.6364 - val_loss: 0.6447 - val_acc: 0.6396\n",
      "Epoch 200/200\n",
      "38528/38678 [============================>.] - ETA: 0s - loss: 0.6455 - acc: 0.6365Epoch 00199: val_loss did not improve\n",
      "38678/38678 [==============================] - 15s - loss: 0.6455 - acc: 0.6366 - val_loss: 0.6442 - val_acc: 0.6401\n",
      "5961/5971 [============================>.] - ETA: 0spredict err=0.6467494964998903, acc=0.6352369787305309\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=adm,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath=\"weights_filter.hdf5\", verbose=1, save_best_only=True)\n",
    "\n",
    "history = History()\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          validation_split=0.1,\n",
    "          nb_epoch=200, batch_size=64,\n",
    "          callbacks=[checkpointer, history])\n",
    "\n",
    "err, acc = model.evaluate(x_test, y_test, batch_size=1)\n",
    "print('predict err=%s, acc=%s'%(err, acc))\n",
    "\n",
    "\n",
    "model_json = model.to_json()\n",
    "with open(\"model_filter.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5931/5971 [============================>.] - ETA: 0spredict err=0.6466877739736132, acc=0.6343995980572769\n"
     ]
    }
   ],
   "source": [
    "# later ...\n",
    "# load json and create model\n",
    "with open('model_filter.json', 'r') as json_file:\n",
    "    loaded_model_json = json_file.read()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "loaded_model.load_weights(\"weights_filter.hdf5\")\n",
    "\n",
    "loaded_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=adm,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "err, acc = loaded_model.evaluate(x_test, y_test, batch_size=1)\n",
    "print('predict err=%s, acc=%s'%(err, acc))\n",
    "\n",
    "hist_loss, val_loss, hist_acc, val_acc = history.history['loss'], history.history['val_loss'], history.history['acc'], history.history['val_acc']\n",
    "np.savetxt('train_history_1_filter.txt', np.array([hist_loss, val_loss, hist_acc, val_acc]).T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
